{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mne\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "files = glob.glob('eeg_data_task_rest/*.edf')\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36, 36)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rest_files = [i for i in files if i[-5] == '1']\n",
    "task_files = [i for i in files if i[-5] == '2']\n",
    "len(rest_files), len(task_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_path):\n",
    "    data = mne.io.read_raw_edf(file_path, preload=True)\n",
    "    data.set_eeg_reference()\n",
    "    data.filter(l_freq = 0.5, h_freq = 50)\n",
    "    epochs = mne.make_fixed_length_epochs(data, duration =5, overlap = 1)\n",
    "    array = epochs.get_data()\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "rest_epochs_array = [read_data(i) for i in rest_files]\n",
    "task_epochs_array = [read_data(i) for i in task_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_epochs_label = [len(i)*[0] for i in rest_epochs_array]\n",
    "task_epochs_label = [len(i)*[1] for i in task_epochs_array]\n",
    "data_list = rest_epochs_array+task_epochs_array\n",
    "label_list = rest_epochs_label+task_epochs_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array = np.vstack(data_list)\n",
    "label_array = np.hstack(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2132, 2500, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_array = np.moveaxis(data_array, 1, 2)\n",
    "data_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv1D, MaxPooling1D, AveragePooling1D, concatenate, Dense, Flatten\n",
    "\n",
    "# Define the input shape\n",
    "input_shape = (2500, 21)\n",
    "# Define the Tception model\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Tception block 1\n",
    "x1 = Conv1D(64, 3, activation='relu', padding='same')(inputs)\n",
    "x1 = MaxPooling1D(2)(x1)\n",
    "\n",
    "x2 = Conv1D(64, 5, activation='relu', padding='same')(inputs)\n",
    "x2 = MaxPooling1D(2)(x2)\n",
    "\n",
    "x3 = Conv1D(64, 7, activation='relu', padding='same')(inputs)\n",
    "x3 = MaxPooling1D(2)(x3)\n",
    "\n",
    "x = concatenate([x1, x2, x3])\n",
    "\n",
    "# Tception block 2\n",
    "x1 = Conv1D(128, 3, activation='relu', padding='same')(x)\n",
    "x1 = AveragePooling1D(2)(x1)\n",
    "\n",
    "x2 = Conv1D(128, 5, activation='relu', padding='same')(x)\n",
    "x2 = AveragePooling1D(2)(x2)\n",
    "\n",
    "x3 = Conv1D(128, 7, activation='relu', padding='same')(x)\n",
    "x3 = AveragePooling1D(2)(x3)\n",
    "\n",
    "x = concatenate([x1, x2, x3])\n",
    "\n",
    "# Flatten and Dense layers\n",
    "x = Flatten()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "# Define the model\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_array, label_array, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 587ms/step - accuracy: 0.7164 - loss: 0.6260 - val_accuracy: 0.7422 - val_loss: 0.5756\n",
      "Epoch 2/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 571ms/step - accuracy: 0.7645 - loss: 0.5553 - val_accuracy: 0.7422 - val_loss: 0.5708\n",
      "Epoch 3/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 590ms/step - accuracy: 0.7571 - loss: 0.5576 - val_accuracy: 0.7422 - val_loss: 0.5720\n",
      "Epoch 4/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 587ms/step - accuracy: 0.7471 - loss: 0.5677 - val_accuracy: 0.7422 - val_loss: 0.5734\n",
      "Epoch 5/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 609ms/step - accuracy: 0.7421 - loss: 0.5737 - val_accuracy: 0.7422 - val_loss: 0.5708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1f67a9af950>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=5, validation_data=(X_test, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F1 score can be calculated as shown in eegnet code which here will come out around to be 0.4-0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.reshape(X_train.shape[0], -1)).reshape(X_train.shape)\n",
    "X_test_scaled = scaler.transform(X_test.reshape(X_test.shape[0], -1)).reshape(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scaled =  Model(inputs=inputs, outputs=outputs)\n",
    "model_scaled.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 902ms/step - accuracy: 0.6474 - loss: 7.5962 - val_accuracy: 0.7609 - val_loss: 0.5996\n",
      "Epoch 2/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 869ms/step - accuracy: 0.7415 - loss: 0.5888 - val_accuracy: 0.7609 - val_loss: 0.5459\n",
      "Epoch 3/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 861ms/step - accuracy: 0.7460 - loss: 0.5573 - val_accuracy: 0.7609 - val_loss: 0.5405\n",
      "Epoch 4/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 869ms/step - accuracy: 0.7396 - loss: 0.5627 - val_accuracy: 0.7609 - val_loss: 0.5370\n",
      "Epoch 5/5\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 879ms/step - accuracy: 0.7496 - loss: 0.5288 - val_accuracy: 0.7625 - val_loss: 0.4988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1ec55c49940>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_scaled.fit(X_train_scaled, y_train, epochs=5, validation_data=(X_test_scaled, y_test), batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that val_loss is decreasing while val_acc isnt, this can be due to low amount of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
